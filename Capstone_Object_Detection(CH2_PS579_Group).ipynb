{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Development [CH2-PS579]\n",
        "\n",
        "\n",
        "*   Muhammad Aditya Hasta Pratama (M299BSY0188) - ML - Universitas Pendidikan Indonesia / Active\n",
        "*   Shereva Miranda (...) - ML - Institut Teknologi Bandung / Active\n",
        "*   Reza Nugraha (...) - ML - Institut Teknologi Bandung / Inactive\n",
        "\n",
        "</br>\n",
        "\n",
        "Reference Tutorial :     \n",
        "\n",
        "*   [Tensorflow 2 Custom Object Detection Model by Lazy Tech](https://www.youtube.com/watch?v=8ktcGQ-XreQ&t=553s&ab_channel=LazyTech).\n",
        "*   [Train a Deep Learning Model for Custom Object Detection Using TensorFlow by TechZizou](https://www.youtube.com/watch?v=amURyS6CAaY&t=69s&ab_channel=techzizou)\n"
      ],
      "metadata": {
        "id": "L9b-rde54YmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPARATION\n",
        "\n",
        "Library and installation that are needed for running the architecture."
      ],
      "metadata": {
        "id": "kUGBQcZaHnOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tensorFlow\n",
        "\n",
        "!pip install tensorflow==\"2.13.0\""
      ],
      "metadata": {
        "id": "xKtipLaT7IgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download models for object detection\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "DmvPDG-O9sDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the object detection API\n",
        "\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "J2ZNn-CiIZVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing model builder\n",
        "\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "8-k1am-FJOdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPARE DATASET\n",
        "\n",
        "Preparing receipt dataset, tfrecords, and labelmap from kaggle."
      ],
      "metadata": {
        "id": "S0685ws1JZ4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kaggle API\n",
        "\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "metadata": {
        "id": "eIljRoWnJr9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting environtment for kaggle API\n",
        "# Change the username or the key to match yours\n",
        "\n",
        "import os\n",
        "\n",
        "username = \"mdhstama23\"\n",
        "key = \"b6eab32f437fce47e2d9ef5a4ac57117\"\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = username\n",
        "os.environ['KAGGLE_KEY'] = key"
      ],
      "metadata": {
        "id": "uHsGtWwbJ0OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "\n",
        "!kaggle datasets download -d mdhstama23/receipt-invoice-ml-ch2ps579 --unzip\n",
        "!ls"
      ],
      "metadata": {
        "id": "gmwP9xeqK5c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create label_map.pbtxt files\n",
        "\n",
        "# Input\n",
        "number_class = 1\n",
        "class_labels = ['total']\n",
        "\n",
        "# Code create\n",
        "label_map_content = ''\n",
        "for idx, label in enumerate(class_labels, start=1):\n",
        "    label_map_content += f\"item {{\\n  id: {idx}\\n  name: '{label}'\\n}}\\n\"\n",
        "\n",
        "labelmap_path = '/content/label_map.pbtxt'  # Change the path as needed\n",
        "with open(labelmap_path, 'w') as labelmap_file:\n",
        "    labelmap_file.write(label_map_content)\n",
        "\n",
        "# Display\n",
        "!cat '/content/labelmap.pbtxt'"
      ],
      "metadata": {
        "id": "JRyQ31FZRDGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the xml-to-csv.py files\n",
        "\n",
        "convert_xml_csv_content = \"\"\"\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "def main():\n",
        "    for folder in ['train', 'test']:\n",
        "        image_path = os.path.join(os.getcwd(), (folder))\n",
        "        xml_df = xml_to_csv(image_path)\n",
        "        xml_df.to_csv(('csv/'+folder+'_labels.csv'), index=None)\n",
        "    print('Successfully converted xml to csv.')\n",
        "\n",
        "main()\n",
        "\"\"\"\n",
        "\n",
        "# Saved the file code\n",
        "\n",
        "# Specify the file path\n",
        "file_path = r\"./content/models/research/object_detection/convert_xml_csv.py\"\n",
        "\n",
        "# Save the code to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(convert_xml_csv_content)\n",
        "\n",
        "print(f\"Code saved to {file_path}\")"
      ],
      "metadata": {
        "id": "APq-p8lqQow6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the xml-to-csv code\n",
        "\n",
        "!python convert_xml_csv.py"
      ],
      "metadata": {
        "id": "ZlmPFWImVUM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tfrecords.py files\n",
        "\n",
        "tfrecords_content = \"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.python.framework.versions import VERSION\n",
        "if VERSION >= \"2.0.0a0\":\n",
        "    import tensorflow.compat.v1 as tf\n",
        "else:\n",
        "    import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "flags.DEFINE_string('image_dir', '', 'Path to images')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'total':\n",
        "        return 1\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
        "    path = os.path.join(FLAGS.image_dir)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()\n",
        "\n",
        "# commands:\n",
        "# python generate_tfrecord.py --csv_input=dataset/test_labels.csv --image_dir=dataset/test --output_path=test.record\n",
        "# python generate_tfrecord.py --csv_input=dataset/train_labels.csv --image_dir=dataset/train --output_path=train.record\n",
        "\"\"\"\n",
        "\n",
        "# Saved the file code\n",
        "\n",
        "# Specify the file path\n",
        "file_path = r\"../content/models/research/object_detection/generate_tfrecord.py\"\n",
        "\n",
        "# Save the code to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(tfrecords_content)\n",
        "\n",
        "print(f\"Code saved to {file_path}\")"
      ],
      "metadata": {
        "id": "HCRx8feFQ2vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tfrecords cod\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=train_labels.csv --image_dir=train --output_path=train.record\n",
        "!python generate_tfrecord.py --csv_input=test_labels.csv --image_dir=test --output_path=test.record"
      ],
      "metadata": {
        "id": "-BHrD-oELAB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ARCHITECTURE OR MODEL CONFIGURATION\n",
        "\n",
        "Configuration training model with model that avaiable in [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ],
      "metadata": {
        "id": "jE89RKrzLh4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "\n",
        "train_record_path = 'train.record'\n",
        "test_record_path = 'test.record'\n",
        "labelmap_path = 'label_map.pbtxt'\n",
        "\n",
        "num_classes = 1\n",
        "fine_tune_checkpoint_type = 'detection'\n",
        "batch_size = 32\n",
        "num_steps = 1000\n",
        "num_eval_steps = 1000"
      ],
      "metadata": {
        "id": "Xr2KuPHCMaWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the architecture\n",
        "# !wget <link model>\n",
        "# !tar -xf <name file model.gz>\n",
        "\n",
        "# model 1\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "!tar -xf efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "\n",
        "# model 2\n",
        "# !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz\n",
        "# !tar -xf faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz"
      ],
      "metadata": {
        "id": "Y-CUUtfrNHsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint initialization\n",
        "\n",
        "# model 1\n",
        "fine_tune_checkpoint = 'efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'\n",
        "\n",
        "# model 2\n",
        "# fine_tune_checkpoint = 'faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8/checkpoint/ckpt-0'"
      ],
      "metadata": {
        "id": "LRryMY8CNc6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the config file\n",
        "# !wget <link config>\n",
        "# base_config_path = <name file config>\n",
        "\n",
        "# model 1\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
        "base_config_path = 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'\n",
        "\n",
        "# model 2\n",
        "# !wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config\n",
        "# base_config_path = 'faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config'"
      ],
      "metadata": {
        "id": "1WWo5XR7PohN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit the config file\n",
        "\n",
        "import re\n",
        "\n",
        "with open(base_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open('model_config.config', 'w') as f:\n",
        "\n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(num_classes), config)\n",
        "\n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
        "\n",
        "  # Set fine-tune checkpoint type to detection\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"',\n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "\n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "\n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"',\n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "\n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "\n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "\n",
        "  f.write(config)"
      ],
      "metadata": {
        "id": "nlXmvYRcTfrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the config file\n",
        "\n",
        "%cat model_config.config"
      ],
      "metadata": {
        "id": "SxMgi0itXUMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING THE MODEL\n",
        "\n",
        "Traiing the model based the architecture configuration before"
      ],
      "metadata": {
        "id": "2RcQ2Nq2XbXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "\n",
        "model_dir = 'training/'\n",
        "pipeline_config_path = 'model_config.config'"
      ],
      "metadata": {
        "id": "SlTUefrgXwfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "id": "A69hMclvX2Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPORT THE MODEL\n",
        "\n",
        "Export the model of training so the model can be used for the next step, which is OCR."
      ],
      "metadata": {
        "id": "z1yDIKdJYG_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export inference graph\n",
        "\n",
        "output_directory = 'inference_graph'\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {model_dir} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_config_path}"
      ],
      "metadata": {
        "id": "xaH4tOd1YSl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model\n",
        "\n",
        "from google.colab import files\n",
        "!zip -r new_model.zip /content/{output_directory}/saved_model\n",
        "files.download(f'new_model.zip')"
      ],
      "metadata": {
        "id": "XFl9nC9jYXZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING IMAGES\n",
        "\n",
        "This step tests whether the model successfully performs object detection"
      ],
      "metadata": {
        "id": "FAJna105Hh5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "testing_content = \"\"\"\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "from tensorflow import tf\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import utility functions for object detection\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile\n",
        "\n",
        "# Function to load the pre-trained model\n",
        "def load_model(model_path):\n",
        "    model = tf.saved_model.load(model_path)\n",
        "    return model\n",
        "\n",
        "# Function to load an image into a numpy array\n",
        "def load_image_into_numpy_array(path):\n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data))\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function to run inference for a single image using the loaded model\n",
        "def run_inference_for_single_image(model, image):\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Run inference\n",
        "    output_dict = model(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(output_dict.pop('num_detections'))\n",
        "    output_dict = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in output_dict.items()}\n",
        "    output_dict['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "    # Handle models with masks:\n",
        "    if 'detection_masks' in output_dict:\n",
        "        # Reframe the bbox mask to the image size.\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "            image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n",
        "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "# Function to run inference on a set of images\n",
        "def run_inference(model, category_index, image_path, output_path):\n",
        "    if os.path.isdir(image_path):\n",
        "        image_paths = []\n",
        "        for file_extension in ('*.png', '*jpg'):\n",
        "            image_paths.extend(glob.glob(os.path.join(image_path, file_extension)))\n",
        "\n",
        "        i = 0\n",
        "        for i_path in image_paths:\n",
        "            image_np = load_image_into_numpy_array(i_path)\n",
        "            # Actual detection.\n",
        "            output_dict = run_inference_for_single_image(model, image_np)\n",
        "            # Visualization of the results of a detection.\n",
        "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np,\n",
        "                output_dict['detection_boxes'],\n",
        "                output_dict['detection_classes'],\n",
        "                output_dict['detection_scores'],\n",
        "                category_index,\n",
        "                instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "                use_normalized_coordinates=True,\n",
        "                line_thickness=8)\n",
        "            plt.imshow(image_np)\n",
        "\n",
        "            # save the output to the specified output folder\n",
        "            plt.savefig(os.path.join(output_path, \"detection_output{}.png\".format(i)))\n",
        "            i = i + 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Parse command line arguments\n",
        "    parser = argparse.ArgumentParser(description='Detect objects')\n",
        "    parser.add_argument('-m', '--model', type=str, required=True, help='Model Path')\n",
        "    parser.add_argument('-l', '--labelmap', type=str, required=True, help='Path to Labelmap')\n",
        "    parser.add_argument('-i', '--image_path', type=str, required=True, help='Path to image (or folder)')\n",
        "    parser.add_argument('-o', '--output_path', type=str, required=True, default='./outputs/', help='Path to output folder (default: outputs/)')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Ensure that the output_path ends with a '/'\n",
        "    if not args.output_path.endswith('/'):\n",
        "        args.output_path += '/'\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(args.output_path, exist_ok=True)\n",
        "\n",
        "    # Load the pre-trained detection model\n",
        "    detection_model = load_model(args.model)\n",
        "    # Create a category index from the label map\n",
        "    category_index = label_map_util.create_category_index_from_labelmap(args.labelmap, use_display_name=True)\n",
        "    # Run inference on the images and save the results to the specified output folder\n",
        "    run_inference(detection_model, category_index, args.image_path, args.output_path)\n",
        "\"\"\"\n",
        "\n",
        "# Saved the file code\n",
        "\n",
        "# Specify the file path\n",
        "file_path = r\"./content/models/research/object_detection/testing_images.py\"\n",
        "\n",
        "# Save the code to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(testing_content)\n",
        "\n",
        "print(f\"Code saved to {file_path}\")"
      ],
      "metadata": {
        "id": "vYsRJqo1Hxye"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Command to run the testing model\n",
        "\n",
        "! python .\\content\\models\\research\\object_detection\\detect_from_image.py -m .\\content\\{output_directory}\\saved_model -l .\\label_map.pbtxt -i .\\test_images -o .\\outputs"
      ],
      "metadata": {
        "id": "0I90LNV4Im2b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}